################################################################################
# simple.qos (Cero3 Shaper)
#
# Abstract:
# This is a multi-band HFSC based shaping script for Ethernet
# gateways. It's based on custom shapers created by Daniel Lakeland for his own use
# it allows realtime priority for certain traffic and then has 4 bands for
# non-realtime traffic
################################################################################
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License version 2 as
# published by the Free Software Foundation.
#
#  Copyright (C) 2012-2016
#    Michael D. Taht, Toke Høiland-Jørgensen, Sebastian Moeller, Daniel Lakeland
#
################################################################################

. ${SQM_LIB_DIR}/defaults.sh

################################################################################

ipt_setup() {

    ipt -t mangle -N QOS_MARK_${IFACE}

    case $QDISC in
        cake*)
            sqm_debug "cake does all the diffserv work - no need for iptables rules"
            ;;
        *)

            # You can go further with classification but...
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS1 -j CLASSIFY --set-class 1:6
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS2 -j CLASSIFY --set-class 1:5
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS0 -j CLASSIFY --set-class 1:4
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS3 -j CLASSIFY --set-class 1:4
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS4 -j CLASSIFY --set-class 1:3
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class AF41 -j CLASSIFY --set-class 1:3	    

	    ## in a world where drr or qfq were available, we could sub-classify the real-time traffic
	    ## but for now pfifo all of it, so it's all the same class
	    ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS5 -j CLASSIFY --set-class 1:2
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS6 -j CLASSIFY --set-class 1:2
            ipt -t mangle -A QOS_MARK_${IFACE} -m dscp --dscp-class CS7 -j CLASSIFY --set-class 1:2
            ;;
    esac

    # Turn it on. Preserve classification if already performed
    #
    #sm: is it correct to do this in $IFACE? Should ingress not be on $DEV? since HTB acts on $DEV?
    #
    # ZERO also does not work on $DEV (that is the IFB will still see the
    # incoming ToS bits whether we squash or not)
    #
    # ZERO is still useful to protect internal machines...
    if [ "$ZERO_DSCP_INGRESS" = "1" ]; then
        sqm_debug "Squashing differentiated services code points (DSCP) from ingress."
        ipt -t mangle -I PREROUTING -i $IFACE -m dscp ! --dscp 0 -j DSCP --set-dscp-class be
    else
        sqm_debug "Keeping differentiated services code points (DSCP) from ingress."
        ipt -t mangle -A PREROUTING -i $IFACE -m mark --mark 0x00/${IPT_MASK} -g QOS_MARK_${IFACE}
    fi

    ipt -t mangle -A POSTROUTING -o $IFACE -m mark --mark 0x00/${IPT_MASK} -g QOS_MARK_${IFACE}

    # The Syn optimization was nice but fq_codel does it for us
    # ipt -t mangle -A PREROUTING -i s+ -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN -j MARK --set-mark 0x01
    # Not sure if this will work. Encapsulation is a problem period

    ipt -t mangle -I PREROUTING -i vtun+ -p tcp -j MARK --set-mark 0x2/${IPT_MASK} # tcp tunnels need ordering

    # Emanating from router, do a little more optimization
    # but don't bother with it too much.

    ipt -t mangle -A OUTPUT -p udp -m multiport --ports 123,53 -j DSCP --set-dscp-class AF42

    #Not clear if the second line is needed
    #ipt -t mangle -A OUTPUT -o $IFACE -g QOS_MARK_${IFACE}

}



hfsc_queue() {

    RATE=$1
    DEV=$2
    
    RTRATE=$((RATE*10/100))
    HIGHRATE=$((RATE*20/100))
    MEDRATE=$((RATE*50/100))
    LOWRATE=$((RATE*15/100))
    BULKRATE=$((RATE*5/100))

    REDMIN=$((RATE * 90/100 * 10/8)) ##bytes in 10ms of packets at burst rate

    
    if [ $((REDMIN < 1500)) ]; then
	REDMIN=1500
    fi
    DUR=$((REDMIN*8*10/RATE/9))
    if [ $((DUR < 25)) eq 1 ]; then
	DUR=25
    fi

    ## we allow at least 25ms of burst time, since this is more than
    ## the interarrival time of VOIP packets, and more than the
    ## interarrival time for 60Hz game packets. This means a
    ## backlogged realtime queue can normally be emptied.

    ## We also expand our duration for slow connections so that we can
    ## always at least send one MTU at the burst rate.

    
    $TC qdisc add dev $DEV root handle 1: `get_stab_string` hfsc default 4
    $TC class add dev $DEV parent 1: classid 1:1 hfsc ls m2 ${RATE}kbit ul m2 ${RATE}kbit

    ## the realtime class will use up to 90% of your uplink speed for up to
    ## DUR ms, in order to reduce latency on bursty traffic. But it's limited to
    ## at most $RTRATE kbit long-term whenever a packet is available on the rt
    ## class, the rt class is scheduled instead of the link share classes, only
    ## if it can't send do link-share classes go
    
    $TC class add dev $DEV parent 1:1 classid 1:2 hfsc rt m1 "$((RATE*90/100))kbit" d ${DUR}ms m2 ${RTRATE}kbit

    ## we'll use RED which is like a FIFO up to a point, and then it
    ## becomes a probabilistically lossy FIFO. This lossiness is an
    ## indicator that our realtime streams are exceeding their
    ## allotted RTRATE, and RED throttles them. Since this realtime
    ## stuff is expected to be mainly UDP, the streams are not
    ## responsive, and we simply drop packets to eliminate them rather
    ## than to signal

    REDMAX=$((REDMIN + RATE*30/8))
    ## always use 30ms above the minimum as the max queue len,
    ## regardless of speed.  we treat the realtime queue like a FIFO
    ## for up to REDMIN of packets, once it gets beyond REDMIN of
    ## packets we ramp up the drop probability until it's 100% drop at
    ## REDMIN + 30ms worth of packets.  This ensures that even with
    ## misbehaving realtime streams our bufferbloat never gets
    ## dramatically above 30ms. it's the job of HFSC to burst-send
    ## fast enough to drain this queue when streams don't
    ## misbehave... so RED's job is to throttle misbehaving realtime
    ## streams by random dropping. If the total stream behaves
    ## properly, the queue should never experience drops
    
    $TC qdisc add dev $DEV parent 1:2 red limit $REDMAX min $REDMIN max $REDMAX probability 1.0
    
    ## remaining classes are non-realtime but 1:3, 1:4, 1:5, 1:6 each have
    ## progressively increased latency.

    ## 1:4 is for most traffic and guaranteed at least 50% of link-share with
    ## full contention

    ## 1:3 will generally give better latency but is limited to only 20% of
    ## link-share at full contention.  1:4 will throttle down to 5% for 80ms to
    ## give other classes better latency but still get 15% of link long term 1:5
    ## will throttle all the way down to 1% of link to give other classes better
    ## latency and only gets 5% long term

    ## under contention between a more limited number of classes, everything
    ## re-scales. for example under contention between 1:4 and 1:6, long term
    ## 1:4 gets MEDRATE/(MEDRATE + BULKRATE) of link and 1:6 gets the rest
    ## similar balancing occurs during the initial 80ms bursts

    ## we choose 80ms burst time because of a variety of things. At the human
    ## scale, an eye-blink is about 100ms so this period is considered small but
    ## noticeable. Also most VOIP works with 20ms between packets, so 80ms is a
    ## small multiple of this time. Finally, at 500kbps "slow" DSL one MTU
    ## packet takes about 24ms so it's a small multiple of the serialization
    ## delay. 

    ## the fq_codel can be allowed to have many packets, as these
    ## streams are less sensitive. We allow 50ms + 3000 bytes of
    ## packets which at 1Mbps = 9250 bytes, and at 1Gbps = 6.25MB. In
    ## any case much less than default of 32MB
    
    FQLIM=$((3000+RATE*50/8))
    
    ## target is the acceptable standing queue delay. Since none of
    ## these are super lag sensitive we can scale this up a
    ## little. The more packets fq_codel has to play with, the better
    ## it can determine who the bulky flows are. We do the larger of
    ## 10ms or 2MTU transfers
    
    TARG=$((2*1500*8/RATE))
    if [ $((TARG < 10)) eq 1 ]; then
	TARG=10
    fi
    
    $TC class add dev $DEV parent 1:1 classid 1:3 hfsc ls m1 "$((RATE*60/100))kbit" d ${DUR}ms m2 ${HIGHRATE}kbit
    $TC qdisc add dev $DEV parent 1:3 fq_codel memory_limit $FQLIM target ${TARG}ms quantum $((1500*2)) ecn
    $TC class add dev $DEV parent 1:1 classid 1:4 hfsc ls m1 "$((RATE*34/100))kbit" d ${DUR}ms m2 ${MEDRATE}kbit
    $TC qdisc add dev $DEV parent 1:4 fq_codel memory_limit $FQLIM target ${TARG}ms quantum $((1500*2)) ecn
    $TC class add dev $DEV parent 1:1 classid 1:5 hfsc ls m1 "$((RATE*5/100))kbit" d ${DUR}ms m2 ${LOWRATE}kbit
    $TC qdisc add dev $DEV parent 1:5 fq_codel memory_limit $FQLIM target ${TARG}ms quantum $((1500*2)) ecn
    $TC class add dev $DEV parent 1:1 classid 1:6 hfsc ls m1 "$((RATE*1/10))kbit" d ${DUR}ms m2 ${BULKRATE}kbit
    $TC qdisc add dev $DEV parent 1:6 fq_codel memory_limit $FQLIM target ${TARG}ms quantum $((1500*2)) ecn

}

egress(){
    hfsc_queue $UPLINK $IFACE
}


ingress() {
    hfsc_queue $DOWNLINK $DEV

    $IP link set dev $DEV up

    # redirect all IP packets arriving in $IFACE to $DEV

    $TC filter add dev $IFACE parent ffff: protocol all prio 10 u32 \
        match u32 0 0 flowid 1:1 action mirred egress redirect dev $DEV

}

sqm_prepare_script() {
    do_modules
    verify_qdisc "hfsc" || return 1
    ipt_setup
}
